\chapter{Writing The Experiment Model}\label{ch:experiment-model}

\section{Introduction}\label{sec:experiment-model-introduction}
In the \textbf{MVCs} design pattern, the \emph{Model} is where you should place the logic and the decisions you make to perform a measurement. In the previous chapter, you started specifying the logic of how you're going to use the DAQ device. You decided, for example, that the device should start and finish with the outputs set to $0\,\textrm{V}$, and that it should handle Pint units for setting and reading values. Even though it was a great start, there are still steps missing to perform a real experiment.

You're still missing, for example, the possibility to perform a scan in a given range of voltages, as there's no way of saving data or the parameters used to generate it. You can develop these tools in a script, which is fine for getting started. At some point, however, you'll want to be systematic, and you won't want to keep editing a script every time you must perform a measurement. You'll want to save data consistently, or you'll want to enable other people to run their experiments based on your routines.

At this moment, the \emph{onion principle} starts making sense. You're slowly building in complexity, one layer at a time. You started with the driver, built some logic on top of it through a device model, and now you can keep growing the complexity by defining an Experiment model. There are many different steps needed to perform a reproducible measurement, and you'll cover them one by one in this chapter. For example, one important aspect you're missing, on top of the ones mentioned earlier, is transforming the voltages you measure to a current, so you can give sense to the \textbf{I} on the I-V curve you're trying to measure.

\tipsInfo{Splitting into Modules}{With a simple device and experiment such as the one you use in this book, sometimes it's hard to put a limit on what should go in the device model and what should go into the experiment model. There are no strict rules. You should always reflect on what you believe is useful in the long run. Once you're comfortable working with classes in Python, splitting the code into reusable, smaller modules does not lead to much more typing.}

There are two extra advantages of developing an experiment model, which become apparent only after working on these topics for a long enough tim. On the one hand, the models are going to lead to reproducible experiments. If you keep track of the parameters, you can go back to precisely the same conditions in which you've performed a specific measurement. On the other hand, having a well-structured model is going to make it very straightforward for you to build a Graphical User Interface ({GUI}) on top of it, though you won't delve further into that subject here.

\section{Writing the Skeleton of an Experiment Model}\label{sec:skeleton-experiment-model}
Every time you want to start developing a model, it's handy to start from an empty skeleton. It helps you to know what parts of the code you need to develop, what things you don't know how to do yet, and what things you still need to learn. It also allows you to have a quick glimpse of how you expect your program to be used. You did this for the device model in the previous chapter, and you can do the same for the experiment model in this chapter. First, create a file called \textbf{experiment.py} inside the \emph{Model} folder, and then think about the steps needed to perform a measurement:

\begin{minted}{python}
class Experiment:
    def __init__(self, config_file):
        pass

    def load_config(self):
        pass

    def load_daq(self):
        pass

    def do_scan(self):
        pass

    def save_data(self):
        pass

    def finalize(self):
        pass

\end{minted}

Most of the code should be self-explanatory, but some steps are worth mentioning. First, you include a \py{.load_config()} method, which will rely on the \py{config_file} you specify at the \py{.__init__()}. Having a separate config file is useful not only to change parameters between measurements, but it helps you with your code. Especially when the number of things you need to remember grows, it's always handy to have a file where you can see how you named things.

You've also included a \py{.load_daq()} method. So far, you only have one DAQ to use, but you can assume that at some point, there may be more than one, so you should have a way of loading one or the other. This can also be a case of premature optimization, in which you anticipate a future that never comes. Nevertheless, it's pedagogically useful to define it here.

The rest of the methods may seem intuitive enough. If you're missing extra pieces, you can always come back and add them. Now it's time to start developing each one of the building blocks.

\section{Writing the Configuration File}\label{sec:configuration-file}
\subsection{Working with YAML files}\label{subsec:yaml-files}
Before you keep developing code, you need to stop for a second to think about what do you want our program to do. You need to think about what inputs you need for our program. For example, you need to know the port to which the device is connected. You also know that you need to define an output and input channel, a range for the scan, a delay between data points. Before going into the details, let's see how to store all these parameters into a text file easily.

In the \emph{Examples} folder, create a file called \textbf{experiment.yml}. You can create the file with any text editor, including the one you're using for editing Python files. The only difference is the extension \emph{yml}. You're going to use this file to hold all the parameters of the experiment. The format fo the file is called {YAML}, which has a straightforward structure; it looks like this:

\begin{minted}{yaml}
Experiment:
  name: This is a test Experiment
  range: [1, 10, 0.1]
  list:
   - first Element
   - second Element
\end{minted}

{YAML} is very simple to read both by a person and by the computer. It has just a few rules. The most important one is that the indentation is \textbf{2} spaces. In the example above, there's a main element called \textbf{Experiment}; everything that is indented compared to that element belongs to it. To read the file, you're going to use a package called PyYAML, which you installed in Chapter~\ref{ch:setting-up}. You can create a file called \textbf{test\_yaml.py} also in the Examples folder to understand how to use these files:

\begin{minted}{python}
import yaml

with open('experiment.yml', 'r') as f:
    e = yaml.load(f, Loader=yaml.FullLoader)

print(e['Experiment'])
for k in e['Experiment']:
    print(k)
    print(e['Experiment'][k])
    print(10*'-')
\end{minted}

You begin by opening the file using \mintinline{python}{open}. You use the \mintinline{python}{with} command because it's convenient for working with files and other resources that have the same pattern of opening/doing/closing. Yaml is then responsible for interpreting the information contained in the file. You store this information in a variable \py{e}, which turns out to be a dictionary.

To get the elements stored in dictionaries, you use keys. In the example above, there's a main key called \py{'Experiment'}, and the sub-keys \py{'name'}, \py{'range'} and \py{'list'}. If you want to use one of those elements, you can type \py{e['Experiment']['name']}, for example. The code prints out each element, separated by a horizontal line. Yaml imported the file directly as a dictionary, but some of the elements are special. You can see that \py{'name'} is a string, but \py{'range'} and \py{'list'} are not. {YAML} automatically detects what kind of information you're storing, making our job easier if you already know what you want to store.

\questionInfo{Exercise}{What type of variables has yaml generated for \py{'range'} and the \py{'list'}? (Remember that you can use \py{type(var)} to know the type of the variable.}

\questionInfo{Exercise}{YAML also supports numeric information. Create a new element and assign it a value of \py{1} or \py{3.14}. What kind of variable has YAML created in such cases?}

Of course, YAML can be used not only to read properties but also to save information generated in a program. Instead of loading data, you can use \py{yaml.dump} method to save it. For example, you can define a dictionary with the following information:

\begin{minted}{python}
d = {'Experiment': {
    'name': 'Name of experiment',
    'range': [1, 10],
    'list': (1, 2, 3),}
}
\end{minted}

If you want to save it to a file, you can do the following:

\begin{minted}{python}
with open('data.yml', 'w') as f:
    f.write(yaml.dump(d, default_flow_style=False))
\end{minted}

You're using the \py{'w'} option to open the file, which means that every time you run the code, it overwrites the file, and you lose the previous contents. After running the code, you can open the file \textbf{data.yml} with any text editor and see that the contents are very similar to the one you created ourselves earlier. One of the advantages of the YAML format is that files are straightforward to read, and don't require much typing.

\questionInfo{Exercise}{Read back the contents of \textbf{data.yml} and check that they are the same you saved.}

\questionInfo{Exercise}{Modify some values in \textbf{data.yml} directly with your text editor and see that those changes are reflected when you reread the file.}

\questionInfo{Exercise}{Create a numpy array and store it using yaml. How does it look like in the file? What happens if you read it back?}

\questionInfo{Exercise: Advanced}{Save a numpy array using yaml. Then activate a virtual environment in which PyYAML is available but not numpy. Try to load the contents of the file. What happens?}

Now that you know how to work with YAML files, it's time to start thinking about the experiment again. You need to stop and think about what do you need to know to perform an experiment.

\questionInfo{Exercise}{Create a new experiment.yml file in the \emph{Examples} folder. Use what you've learned about YAML files to write a file that contains all the information that you need to perform an experiment and interpret its data. For example, knowing \emph{who} performed an experiment may be important.}

\subsection{Loading the config file}\label{subsec:loading-the-config}
You've decided to use YAML files because of their simplicity, and because it's easy to map them to dictionaries in Python. The main advantage of having a separated config file is not only that it allows us to run different measurements changing parameters as you desire, but that it also helps us keep our code well organized. You always know how to get the information you need, just by looking at the config file.

First, you need to decide what you're going to include in the configuration file. The information is not static, and it may happen that after working for a while, you realize there's some important parameter missing or that something you thought was important is not necessary anymore. Every time you find ourselves deciding a value, that information should go to the config file. For example, if you need to decide in which port the DAQ is connected, that goes to the config file. You're going to use the \textbf{experiment.yml} file in the \emph{Examples} folder to store all this information. Below, you show how the config file could look like. You've included extra options that you haven't discussed yet, such as the user performing the experiment, which can be relevant for bookkeeping:

\begin{minted}{text}
User:
  name: Aquiles

DAQ:
  name: AnalogDaq
  port: /dev/ttyACM0

Scan:
  start: 0V
  stop: 3.2V
  step: 400mV
  channel_out: 0
  channel_in: 0
  delay: 100ms

Saving:
  filename: data.dat # Files won't be overwritten, but renamed as data_001.dat, etc.
\end{minted}

You haven't used a primary key such as \emph{experiment} because it does not add anything, and forces us to type more. If for some reason, you needed to store parameters for two different experiments on the same file, then you could add two top-level keys such as \py{Experiment_1}, \py{Experiment_2}. The parameters above are enough to get started and then slowly keep adding or modifying when you need it. There are some glaring omissions, meant to trigger discussions further down the road. If you've already spotted them, you've done an excellent job, but don't stress yourself if you haven't.

You've to update the \py{Experiment} class to load the file. You're storing the filename within the class, so all our methods can be triggered without arguments. But this is just a choice we've made:

\begin{minted}{python}
import yaml

class Experiment:
    def __init__(self, config_file):
        self.config_file = config_file

    def load_config(self):
        with open(self.config_file, 'r') as f:
            data = yaml.load(f, Loader=yaml.FullLoader)
        self.config = data
\end{minted}

You've used the same code you showed in the previous Section but as part of a method. When you load the configuration file, it's stored as an attribute of the Experiment class, called \py{self.config}. Now that the experiment is starting to have shape, you can create a file to show how to use it and check whether you're doing things properly. In the \emph{Examples} folder, you can create a file called \textbf{run\_experiment.py}, and add the following:

\begin{minted}{python}
import sys
import os

base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(base_dir)

from PythonForTheLab.Model.experiment import Experiment

experiment = Experiment('experiment.yml')
experiment.load_config()
print(experiment.config)
\end{minted}

You use the strategy explained in Section~\ref{sec:path} to let Python know where to find our program. The rest is easy to understand; you start an experiment, load the config file, and print the parameters that you've loaded. So far, you're not doing much, but it's a good start.

Now you've a consistent interface for loading the configuration file into our programs. It gives us a great deal of flexibility and makes the code nicely reusable and extendable.

\questionInfo{Exercise}{When the function \py{load_config} loads the configuration from a file, verify that some essential parameters are defined. For example, verify that there's a user associated with an experiment. If something is missing, print an error message or raise an Exception.}

\section{Loading the DAQ}\label{sec:loading-daq}
To load the DAQ into our experiment, you can start with the simplest approach. You import the model for the daq, and you initialize it using the \py{load_daq} method. You can update the experiment model (we omitted some parts of the code for brevity):

%! Suppress = Ellipsis
\begin{minted}{python}
from PythonForTheLab.Model.analog_daq import AnalogDaq

[...]

def load_daq(self):
    self.daq = AnalogDaq(self.config['DAQ']['port'])
    self.daq.initialize()
\end{minted}

The \py{load_daq} method uses the information stored in the configuration file to instantiate and initialize the daq model. Having a config file in YAML format makes it very easy to navigate and find where is located the information of the port for the daq. The main key is \py{DAQ}, and the sub-key is \py{port}. In this way, there are many fewer things you need to keep in our heads. You can always go back to the file and read what you need to know. You've also decided that you initialize the device right after loading it. You could have developed a separate method, but at this stage and for this experiment, there's no real need.

Since you're taking care of loading and initializing the DAQ, you can also develop the finalize method, which takes just one line:

\begin{minted}{python}
def finalize(self):
    self.daq.finalize()
\end{minted}

You can update the \textbf{run\_experiment.py} file to reflect the additions you've just made to the Experiment:

%! Suppress = Ellipsis
\begin{minted}{python}
[...]
experiment.load_daq()
print(experiment.daq)
experiment.finalize()
\end{minted}

When you run the code above, you see that the output of \py{print(experiment.daq)} is not pretty, and it's hard to understand. You can update the device model to make the string that appears on screen nicer. You edit the \textbf{analog\_daq.py} file to include the following method in the \py{AnalogDaq} class:

%! Suppress = Ellipsis
\begin{minted}{python}
[...]

class AnalogDaq:
[...]

    def __str__(self):
        return "Analog Daq"
\end{minted}

The method \py{__str__} is called a \emph{dunder} method, because it has the double underscore before and after its name. These are magic methods in classes that allow us to change the behavior at a much lower level. The \emph{str} method is responsible for letting Python know how to transform an object to a string. It happens, for example, when you use the \py{print} function. If you rerun the experiment, you see that the output is clearer than before.

\infoInfo{String Representation}{Adding a string representation to the classes you build is an excellent addition but not mandatory. You should be careful not to derail on details that don't bring us close to the goal of performing a measurement.}

\subsection{Including the dummy DAQ}\label{subsec:loading-dummy-daq}
In the previous chapter, you took a small detour when you discussed the creation of a base class for the device models. In Section~\ref{sec:base-model}, you also discussed creating a dummy device, a fake model that outputs random numbers when requested. It means that you've two different DAQ devices you can use, one real and one fake. Therefore, you can improve the Experiment model to accommodate the possibility of using one or the other. You're going to follow a non-standard approach, which does not comply with the general principles of Python, but that it's nevertheless convenient. In the config file, you included the name of the DAQ, and it's time to use this information. There will be two possibilities, either \py{AnalogDaq}, or \py{DummyDaq}:

\begin{minted}{python}
def load_daq(self):
    name = self.config['DAQ']['name']
    port = self.config['DAQ']['port']
    if name == 'DummyDaq':
        from PythonForTheLab.Model.dummy_daq import DummyDaq
        self.daq = DummyDaq(port)

    elif name == 'AnalogDaq':
        from PythonForTheLab.Model.analog_daq import AnalogDaq
        self.daq = AnalogDaq(port)

    else:
        raise Exception('The daq specified is not yet supported')

    self.daq.initialize()
\end{minted}

The \py{load_daq} method is now much more powerful than before, and you're doing something that may seem strange at first sight. You're importing Python modules not at the top of the file, but deep inside a method. It's not standard, and in some contexts, it's discouraged, but it's crucial to understand why you've decided to follow this approach. When working with real devices, the models may depend on drivers that are not installed on the computer. If you import the device model at the top of the experiment file, you may get an error because of a device you do not intend to use.

On the other hand, this behavior is discouraged because if there's a problem in one of the modules, you won't notice it until you're running the program, and that can be a waste of our time and, more importantly, of data. For example, \py{AnalogDaq} depends on having a proper controller available. If you make the import at the top of the class, and the controller is not in place, you get an error even before you instantiate the experiment class. If you plan to use only the dummy model, then you don't care about this. The balance between safety, best practices, and ease of development is sometimes hard to choose. What is important to remember is that Python is an incredibly flexible language.

You've also included a final clause in our if-statement to raise an exception if the specified model is not one of the two with which you know how to work. The advantage of having models that specify the same API is that after you load and instantiate them, they both work in the same way. Therefore the rest of our code is completely independent of which model you're using.

\questionInfo{Exercise}{In Section~\ref{sec:pint} you included units for the \py{AnalaogDaq} class, but you didn't add units for the \py{DummyDaq}. It's an inconsistency since both models are going to generate different types of output. Update the dummy model to generate random values including units of volts.}

\section{Performing a Scan}\label{sec:doing-scan}
The core of the experiment model is being able to perform a scan, changing the voltages on the output, and reading the voltages in the input. This kind of measurement is widespread in a lot of different experiments, not only in electronics. That is the reason you decided to call it \py{scan}, which is a fairly generic name.

\questionInfo{Exercise}{Think at least three different examples of experiments that you can perform by changing an analog output and recording an analog input.}

To perform a scan, you use the parameters that you've defined in the \py{Scan} Section of the config file. Since you already performed this type of measurement either from the command line or from example files, it's easy to adapt to what you did to the method in the Experiment class:

%! Suppress = Ellipsis
\begin{minted}{python}
from PythonForTheLab import ur
[...]

def do_scan(self):
    start = ur(self.config['Scan']['start'])
    stop = ur(self.config['Scan']['stop'])
    step = ur(self.config['Scan']['step'])
\end{minted}

After the first few lines, you need to stop and think. After you introduced units to our model, you didn't try to perform a scan, and therefore you need to see how Pint works. You know that \py{start}, \py{stop}, and \py{step} all have units of volts or related. However, if you try to use the start, stop, and step values as they are, you will fail. Nore the Python \py{range} function, nor Numpy's \py{arange} know how to deal with quantities. However, Pint allows us to transform a quantity to a plain number in given units, by using the \py{m_as} method. Therefore, if you want to have a range of values over which to perform the scan, you can do this:

\begin{minted}{python}
scan_range = np.arange(start.m_as('V'), stop.m_as('V'), step.m_as('V'))
\end{minted}

If you explore the \py{scan_range} variable, you will see that it includes the numbers starting with \py{start}, going in increments of \py{step}, but it does not include the \py{stop} value. This is not a bug, but just how \py{arange} works. The documentation clearly states that arange generates values in the semi-open interval $[\textrm{start}, \textrm{stop})$. If you want to include the last point or not, is debatable. On possible strategy would be to do this:

\begin{minted}{python}
scan_range = np.arange(start.m_as('V'), stop.m_as('V')+step.m_as('V'), step.m_as('V'))
\end{minted}

But this has an associated risk. What happens if start is $0\,\textrm{V}$, stop is $3.3\,\textrm{V}$ and step is $0.5\,\textrm{V}$? The last value in the range would be higher than $3.3\,\textrm{V}$. It means that forcing the stop to be larger only works if the step divides the range in an integer number of intervals.

You could use numpy's \py{linspace}, which allows us to generate equally spaced values if you provide a start, stop and the number of points you want. This seems like a viable solution. You can do the following:

\begin{minted}{python}
num_points = int((stop.m_as('V')-start.m_as('V'))/step.m_as('V'))+1
scan_range = np.linspace(start.m_as('V'), stop.m_as('V'), num_points)
\end{minted}

You added a \py{+1} to the number of points to accommodate the last value. For example, if you wanted all the integer numbers from 0 to 10, you should use 11 data points. Again, this works fine if the number of points is an integer value, but as soon as the step you specified does not divide the interval in an integer number of points, you would have a problem. With the same values used before, you would get a scan range like this:

\begin{minted}{python}
array([0.  , 0.55, 1.1 , 1.65, 2.2 , 2.75, 3.3 ])
\end{minted}

Which is not spaced by $0.5\,\textrm{V}$, but it respects the start and stop values. The last option to which you can resource is to change the config file. You thought that defining the step was a good idea, but perhaps it's a better idea to use the number of steps you want in our scan instead of the step size. Therefore, you've to update \textbf{experiment.yml} to include the number of steps and not the step size:

\begin{minted}{text}
Scan:
  start: 0V
  stop: 3.3V
  num_steps: 100
  channel_out: 0
  channel_in: 0
  delay: 100ms
\end{minted}

Before you proceed with the experiment class, you see that the array that numpy generates has no units, and this makes sense because you stripped the units from the parameters of the scan. But this can be easily solved by multiplying the array with the proper units, like the code below shows:

%! Suppress = Ellipsis
\begin{minted}{python}
from time import sleep
import numpy as np
[...]

def do_scan(self):
    start = ur(self.config['Scan']['start']).m_as('V')
    stop = ur(self.config['Scan']['stop']).m_as('V')
    num_steps = int(self.config['Scan']['num_steps'])
    delay = ur(self.config['Scan']['delay'])
    scan_range = np.linspace(start, stop, num_steps) * ur('V')
    scan_data = np.zeros(num_steps)
    i = 0
    for volt in scan_range:
        self.daq.set_voltage(self.config['Scan']['channel_out'], volt)
        measured_voltage = self.daq.get_voltage(self.config['Scan']['channel_in'])
        scan_data[i] = measured_voltage
        i += 1
        sleep(delay.m_as('s'))
\end{minted}

The \py{do_scan} method is very complete now. You use the number of steps specified in the config file, you're also using the delay, and therefore you import \py{sleep} at the top of the file. Then you go through all the voltages. You also defined a variable called \py{scan_data} to hold the values as you measure them. It's a big achievement, and you need to reflect it the file you were using for testing the Experiment class. You can update \textbf{run\_experiment.py}:

%! Suppress = Ellipsis
\begin{minted}{python}
[...]
experiment.do_scan()
experiment.finalize()
\end{minted}

When you run the experiment, you encounter a problem:

%! Suppress = Ellipsis
\begin{minted}{python}
...

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: setting an array element with a sequence.
\end{minted}

It's because of how Pint and numpy work together. You can't simply put into a numpy array a quantity. However, solving this problem is very straightforward. In the same way you defined the \py{scan_range} as an array with units, you can define \py{scan_data} to also include units:

\begin{minted}{python}
scan_data = np.zeros(num_steps) * ur('V')
\end{minted}

And you can go ahead now and run the experiment without errors. After you do the scan you can finalize the experiment, but there's no way for us to actually look at the data that you acquired. To make the data available to the outside world, or to other methods in the same class, you can define attributes instead of just variables that get destroyed when the method finishes. The \py{do_scan} method can then look like this:

\begin{minted}{python}
def do_scan(self):
    start = ur(self.config['Scan']['start']).m_as('V')
    stop = ur(self.config['Scan']['stop']).m_as('V')
    num_steps = int(self.config['Scan']['num_steps'])
    delay = ur(self.config['Scan']['delay'])
    self.scan_range = np.linspace(start, stop, num_steps) * ur('V')
    self.scan_data = np.zeros(num_steps) * ur('V')
    i = 0
    for volt in self.scan_range:
        self.daq.set_voltage(self.config['Scan']['channel_out'], volt)
        measured_voltage = self.daq.get_voltage(self.config['Scan']['channel_in'])
        self.scan_data[i] = measured_voltage
        i += 1
        sleep(delay.m_as('s'))
\end{minted}

You altered both \py{scan_range} and \py{scan_data}, so you can now go back to the \textbf{run\_experiment.py} file and print the values you acquired:

%! Suppress = Ellipsis
\begin{minted}{python}
[...]

experiment.do_scan()
print(experiment.scan_range)
print(experiment.scan_data)
experiment.finalize()
\end{minted}

Finally, you can see the data you acquired after the scan runs. It would allow us to do plenty of things like saving, plotting, analyzing. But you should not go ahead of ourselves at this stage. You had laid out a plan for the Experiment class, and you should follow it as much as you can. The strategy of adding \py{self.} before a variable is beneficial, and this is the real power of objects. The idea is that you should use objects when you need to maintain \emph{state}. It's not just a function that runs and returns a value, but it's updating the \emph{state} of the experiment, or the device.

Now you can proceed further to the last missing step: saving data.

\section{Saving Data to a File}\label{sec:saving-data}
After you perform a scan, you must save both the data and the \emph{metadata}. With metadata you mean information on the parameters used to perform an experiment and that would allow us or anybody else to repeat the measurement. Let's start by the beginning, just saving data to a file, you're going to use the built-in functions of numpy for this, because you've to save two arrays: \py{scan_data} and \py{scan_range}. And since you already know that Pint and Numpy interact in special ways, you anticipate the errors that may appear:

\begin{minted}{python}
def save_data(self):
    data = np.vstack([self.scan_range, self.scan_data]).T
    header = "Scan range in 'V', Scan Data in 'V'"
    filename = self.config['Saving']['filename']
    np.savetxt(filename, data.m_as('V'), header=header)
\end{minted}

The method above works. You can go ahead and run the experiment, and it generates a file with two columns (that is the reason for the \py{vstack} and the \py{.T}) and a header specifying that the data is in units of Volts. However, if you run the experiment for a second time, the data gets overwritten. Moreover, you're saving the data to the same folder where you run the experiment, and this is a terrible idea, you would like to save the data in a dedicated place. Therefore, you need to update the config file first, and then the saving method. The folder you're using for saving data is only an example, and one should change it according to their needs:

\begin{minted}{text}
Saving:
  filename: data.dat # Files won't be overwritten, but renamed as data_001.dat, etc.
  folder: /home/aquiles/Data
\end{minted}

Something handy when saving data is to organize it by dates. You can create a folder with the date of the measurement inside the \emph{Data} folder. First, you see snippets to understand what you need, and then you add the modifications to the method itself. To get the date of today as a string, you can combine the \py{datetime} package and the formatting of strings:

\begin{minted}{pycon}
>>> from datetime import datetime
>>> print(datetime.today())
2020-04-13 12:22:34.895038
>>> print(f'{datetime.today():%Y-%m-%d}')
2020-04-13
\end{minted}

The first part is there, you know how to get the folder name based on todays date. Now you've to create the folder if it does not exist:

\begin{minted}{pycon}
>>> import os
>>> data_folder = '/home/aquiles/Data'
>>> today_folder = f'{datetime.today():%Y-%m-%d}'
>>> saving_folder = os.path.join(data_folder, today_folder)
>>> os.path.isdir(saving_folder)
False
>>> os.makedirs(saving_folder)
>>> os.path.isdir(saving_folder)
True
\end{minted}

Using the package \py{os} allows us to take care of the common problems that appear when dealing with directories. For example, Linux uses \texttt{/} to separate the structure, while Windows uses \texttt{\\}. Also, you may define the folder with a trailing \texttt{/} or not. \py{os} takes care of all this complexity for us. You join the data folder and today's folder and check if it exists, if it doesn't, you create it. The \py{makedirs} also creates the missing parent directories. For example, if the \emph{Data} folder does not exist, the program creates it.

Next, you've to be sure you will not overwrite the files when you save new scans. Ideally, you would like the files to look like \py{data_001.dat}, \py{data_002.dat}, etc. Using what you specified in the config file, you can achieve something like it:

\begin{minted}{python}
>>> filename = 'data.dat'
>>> base_name = filename.split('.')[0]
>>> ext = filename.split('.')[-1]
>>> i = 1
>>> new_filename = f'{base_name}_{i:04d}.{ext}'
>>> print(new_filename)
data_0001.dat
\end{minted}

It seems like much work just to format the name, but once you've it, you can use it in all our experiments. You only need to know which is the first available name and save data there. You're now ready to save the data, and also the metadata:

%! Suppress = Ellipsis
\begin{minted}{python}
import os
from datetime import datetime
[...]

def save_data(self):
    data_folder = self.config['Saving']['folder']
    today_folder = f'{datetime.today():%Y-%m-%d}'
    saving_folder = os.path.join(data_folder, today_folder)
    if not os.path.isdir(saving_folder):
        os.makedirs(saving_folder)

    data = np.vstack([self.scan_range, self.scan_data]).T
    header = "Scan range in 'V', Scan Data in 'V'"

    filename = self.config['Saving']['filename']
    base_name = filename.split('.')[0]
    ext = filename.split('.')[-1]
    i = 1
    while os.path.isfile(os.path.join(saving_folder, f'{base_name}_{i:04d}.{ext}')):
        i += 1
    data_file = os.path.join(saving_folder, f'{base_name}_{i:04d}.{ext}')
    metadata_file = os.path.join(saving_folder, f'{base_name}_{i:04d}_metadata.yml')
    np.savetxt(data_file, data.m_as('V'), header=header)
    with open(metadata_file, 'w') as f:
        f.write(yaml.dump(self.config, default_flow_style=False))
\end{minted}

The \py{save_data} method may be the most complex in the program, but it's also powerful. You start with a base folder and create a folder with the current date, with the format Year-Month-Day. You format the data to make it easy to store as two columns on a text file, and you also add a header to explain what you're storing. You extract the base part of the filename and the extension as two separate variables, and you format the filename in such a way that it can have a number appended to it. The syntax \py{i:04d} is the secret to formating numbers with an appropriate number of $0$ in front. You use a while loop to increase the counter until the first file is available, and use that value to store the data. You also create another file with the same number and a similar name, to store the metadata. In our case, the metadata is nothing more than the \py{config} dictionary.

\checkInfo{Saving Metadata}{A convenient by-product of saving the config as a YAML file is that you can use it as the config file for the next experiment. If you want to repeat a measurement from the past, you just need to point the experiment to the config you saved from that date.}

You can update the \textbf{run\_experiment.py} file, and perform a complete measurement:

\begin{minted}{python}
import sys
import os

base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(base_dir)

from PythonForTheLab.model.experiment import Experiment

experiment = Experiment('experiment.yml')
experiment.load_config()

experiment.load_daq()

experiment.do_scan()
experiment.save_data()
experiment.finalize()
\end{minted}

Except for the part of appending the folder to the system path, you can run a relatively complex experiment in less than 10 lines of code, including saving data and metadata. Being able to reduce a complex problem to a relatively simple flow is thanks to the effort you put into defining the proper methods in the experiment and device models.

\section{Conclusions}\label{sec:experiment-model-conclusions}
With this chapter, you've finished the core code for a functioning experiment. Defining an Experiment model is one of the best strategies to simplify the work needed to perform a measurement. Once the complicated bits of code, such as doing a scan or saving data are in place, our running script just needs one line of code. The model takes care of rest automatically. If you share the code with a colleague and you show them the \py{run_experiment} script, they will be able to perform their measurements in no time.

You still left some more things that you should do in our experiment. For example, you're still acquiring voltages instead of currents. You're not going to explicitly solve this problem because it's an excellent exercise to start thinking by yourself.

\questionInfo{Exercise}{Update the config file to include information on the resistance that you're using. With that value, update the \py{do_scan} method to acquire amperes (or milliamperes) instead of volts. Finally, you need to update the save method to accommodate for the changes, not only in the header but also in how you transform the arrays to unitless before saving them.}

Some other topics which are still relevant and that you're going to cover on the next chapter include how to change the parameters of the scan directly from within the running script. It would allow us to, for example, scan the voltages with varying delays to understand if there's some form of hysteresis or scans with an increased resolution around specific features. You've also neglected what would happen if someone forgets to load the config file or the daq before starting a scan, for example.

The final missing bit is how to stop the experiment while it's running. If you see something is going wrong, there's no way of deciding to stop it without losing data. There are a lot of different approaches to solving this. The one you're going to explore is based on \emph{Threads}, a handy tool for developing acquisition software, but that may have a somewhat high entry barrier for newcomers to Python.
